{
  "steps": [
    {
      "type": "read_files",
      "config": {
        "path": "{{ candidate_spec_path }}",
        "content_key": "candidate_spec",
        "merge_mode": "dict"
      }
    },
    {
      "type": "llm_generate",
      "config": {
        "prompt": "You are an expert developer evaluating a candidate component specification to determine if it has enough context for effective implementation. You'll analyze the candidate specification and identify any areas that need clarification or additional information.\n\nCandidate Specification:\n{{ candidate_spec }}\n\nComponent ID: {{ component_id }}\n\n{% if component_docs_spec_guide %}\nUse the following guide as your evaluation criteria:\n<COMPONENT_DOCS_SPEC_GUIDE>\n{{ component_docs_spec_guide }}\n</COMPONENT_DOCS_SPEC_GUIDE>\n{% endif %}\n\n{% if implementation_philosophy %}\n<IMPLEMENTATION_PHILOSOPHY>\n{{ implementation_philosophy }}\n</IMPLEMENTATION_PHILOSOPHY>\n{% endif %}\n\n{% if modular_design_philosophy %}\n<MODULAR_DESIGN_PHILOSOPHY>\n{{ modular_design_philosophy }}\n</MODULAR_DESIGN_PHILOSOPHY>\n{% endif %}\n\nPerform a systematic evaluation of the candidate specification with these steps:\n\n1. Identify the component name and type (if possible)\n2. Determine if a clear purpose statement exists\n3. Check if core requirements are well-defined and specific\n4. Assess if implementation considerations are provided\n5. Evaluate whether component dependencies are properly identified\n6. Check if error handling approaches are specified\n7. Look for any information about future considerations\n\nFor each aspect, provide:\n- A score from 1-5 (1=Missing/Insufficient, 5=Excellent)\n- Brief explanation of the score\n- Specific clarification questions if the score is 3 or lower\n\nFormat your response with these sections:\n1. Overall Assessment - Brief overview with readiness determination\n2. Scoring Summary - Table with scores for each aspect\n3. Detailed Analysis - Detailed assessment of each aspect with clarification questions\n4. Improvement Recommendations - List of questions to improve the specification\n\nBe constructive but thorough in your assessment.",
        "model": "{{ model }}",
        "output_format": "files",
        "output_key": "evaluation_result"
      }
    },
    {
      "type": "llm_generate",
      "config": {
        "prompt": "Format the specification evaluation as a proper markdown file with informative title and sections.\n\nEvaluation Result:\n{{ evaluation_result }}\n\nComponent ID: {{ component_id }}\n\nFormat your response as a structured markdown file. \n\nIf the evaluation determined that the specification needs significant clarification (average score below 4.0), name the file '{{ component_id }}_needs_clarification.md'. If the specification was deemed sufficient (average score 4.0 or higher), name the file '{{ component_id }}_evaluation_summary.md'.\n\nDo not include any subdirectories in the path.",
        "model": "{{ model }}",
        "output_format": "files",
        "output_key": "formatted_evaluation"
      }
    },
    {
      "type": "write_files",
      "config": {
        "files_key": "formatted_evaluation",
        "root": "{{ output_root }}"
      }
    }
  ]
}
